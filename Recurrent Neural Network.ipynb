{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "from random import randint\n",
    "import datetime\n",
    "import time\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Removes punctuation, parentheses, question marks, etc., and leaves only alphanumeric characters\n",
    "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "\n",
    "def cleanSentences(string):\n",
    "    string = string.lower().replace(\"<br />\", \" \")\n",
    "    return re.sub(strip_special_chars, \"\", string.lower())\n",
    "\n",
    "maxSeqLength = 20 #Maximum length of sentence\n",
    "numDimensions = 300 #Dimensions for each word vector\n",
    "    \n",
    "wordsList = np.load('wordsList.npy')\n",
    "wordsList = wordsList.tolist() #Originally loaded as numpy array\n",
    "wordsList = [word.decode('UTF-8') for word in wordsList] #Encode words as UTF-8\n",
    "wordVectors = np.load('wordVectors.npy')\n",
    "\n",
    "# generate log files here\n",
    "ts = time.time()\n",
    "st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive files finished\n",
      "Negative files finished\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cc2cef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "positiveFiles = ['positive/' + f for f in listdir('positive/') if isfile(join('positive/', f))]\n",
    "negativeFiles = ['negative/' + f for f in listdir('negative/') if isfile(join('negative/', f))]\n",
    "numWords = []\n",
    "for pf in positiveFiles:\n",
    "    with open(pf, \"r\", encoding='utf-8') as f:\n",
    "        line=f.readline()\n",
    "        counter = len(line.split())\n",
    "        numWords.append(counter)       \n",
    "print('Positive files finished')\n",
    "\n",
    "minLength = len(positiveFiles)\n",
    "\n",
    "for nf in negativeFiles:\n",
    "    with open(nf, \"r\", encoding='utf-8') as f:\n",
    "        line=f.readline()\n",
    "        counter = len(line.split())\n",
    "        numWords.append(counter)  \n",
    "print('Negative files finished')\n",
    "\n",
    "if (minLength > len(negativeFiles)):\n",
    "    minLength = len(negativeFiles)\n",
    "\n",
    "numFiles = len(numWords)\n",
    "\n",
    "ids = np.zeros((minLength*2, maxSeqLength), dtype='int32')\n",
    "labels = []\n",
    "fileCounter = 0\n",
    "counter = 0\n",
    "for pf in positiveFiles:\n",
    "    if (counter >= minLength):\n",
    "        break\n",
    "    with open(pf, \"r\") as f:\n",
    "        indexCounter = 0\n",
    "        line=f.readline()\n",
    "        cleanedLine = cleanSentences(line)\n",
    "        split = cleanedLine.split()\n",
    "        for word in split:\n",
    "            try:\n",
    "                ids[fileCounter][indexCounter] = wordsList.index(word)\n",
    "            except ValueError:\n",
    "                ids[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "            indexCounter = indexCounter + 1\n",
    "            if indexCounter >= maxSeqLength:\n",
    "                break\n",
    "        labels.append([1,0])\n",
    "        fileCounter = fileCounter + 1\n",
    "        counter = counter + 1\n",
    "\n",
    "counter = 0\n",
    "for nf in negativeFiles:\n",
    "    if (counter > minLength):\n",
    "        break\n",
    "    with open(nf, \"r\") as f:\n",
    "        indexCounter = 0\n",
    "        line=f.readline()\n",
    "        cleanedLine = cleanSentences(line)\n",
    "        split = cleanedLine.split()\n",
    "        for word in split:\n",
    "            try:\n",
    "                ids[fileCounter][indexCounter] = wordsList.index(word)\n",
    "            except ValueError:\n",
    "                ids[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "            indexCounter = indexCounter + 1\n",
    "            if indexCounter >= maxSeqLength:\n",
    "                break\n",
    "        labels.append([0,1])\n",
    "        fileCounter = fileCounter + 1 \n",
    "        counter = counter + 1\n",
    "#Pass into embedding function and see if it evaluates. \n",
    "\n",
    "labels = np.asarray(labels)\n",
    "np.save('idsMatrix', ids)\n",
    "np.save('labels', labels)\n",
    "\n",
    "plt.hist(numWords, 50)\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axis([0, 50, 0, 1000])\n",
    "plt.show()\n",
    "plt.savefig(\"figures/{}-histogram.png\".format(st), format='png')\n",
    "# generate log files here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = np.load('idsMatrix.npy')\n",
    "labels = np.load('labels.npy')\n",
    "\n",
    "ids, labels = shuffle(ids, labels, random_state = 0)\n",
    "lastTrainingIndex = int(round(len(ids) * .90))\n",
    "ids = np.split(ids, [lastTrainingIndex, len(ids)])\n",
    "labels = np.split(labels, [lastTrainingIndex, len(labels)])\n",
    "trainingLabels = labels[0]\n",
    "testingLabels = labels[1]\n",
    "trainingIds = ids[0]\n",
    "testingIds = ids[1]\n",
    "\n",
    "def getTrainBatch(counter):\n",
    "    label = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        arr[i] = trainingIds[counter-1:counter]\n",
    "        label.append(trainingLabels[counter-1])\n",
    "        if (counter >= len(trainingIds) - 1):\n",
    "            counter = 1\n",
    "        else:\n",
    "            counter = counter + 1\n",
    "    return arr, label, counter\n",
    "\n",
    "def getTestBatch(counter):\n",
    "    label = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        arr[i] = testingIds[counter-1:counter]\n",
    "        label.append(testingLabels[counter-1])\n",
    "        if (counter >= len(testingIds) - 1):\n",
    "            counter = 1\n",
    "        else:\n",
    "            counter = counter + 1\n",
    "    return arr, label, counter\n",
    "\n",
    "batchSize = 24\n",
    "lstmUnits = 64\n",
    "numClasses = 2\n",
    "iterations = 1000\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "labels = tf.placeholder(tf.float32, [batchSize, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, maxSeqLength])\n",
    "\n",
    "data = tf.Variable(tf.zeros([batchSize, maxSeqLength, numDimensions]),dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(wordVectors,input_data)\n",
    "\n",
    "lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n",
    "lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\n",
    "value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)\n",
    "\n",
    "weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n",
    "value = tf.transpose(value, [1, 0, 2])\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = (tf.matmul(last, weight) + bias)\n",
    "\n",
    "correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "tf.summary.scalar('Loss', loss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "for i in range(iterations):\n",
    "   #Next Batch of reviews\n",
    "   nextBatch, nextBatchLabels, counter = getTrainBatch(counter)\n",
    "   sess.run(optimizer, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "   \n",
    "   #Write summary to Tensorboard\n",
    "   if (i % 50 == 0):\n",
    "       summary = sess.run(merged, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "       writer.add_summary(summary, i)\n",
    "\n",
    "   #Save the network every 10,000 training iterations\n",
    "   if (i % 10000 == 0 and i != 0):\n",
    "       save_path = saver.save(sess, \"models/pretrained_lstm.ckpt\", global_step=i)\n",
    "       print(\"saved to %s\" % save_path)\n",
    "writer.close()\n",
    "\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/pretrained_lstm.ckpt-100000\n"
     ]
    }
   ],
   "source": [
    "saver.restore(sess, tf.train.latest_checkpoint('models'))\n",
    "\n",
    "counter = 1\n",
    "\n",
    "iterations = 10000\n",
    "# for i in range(iterations):\n",
    "#     nextBatch, nextBatchLabels, counter = getTestBatch(counter)\n",
    "#     print(\"Accuracy for this batch:\", (sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})) * 100)\n",
    "#     runlog.write(\"Accuracy for this batch: {}\\n\".format((sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})) * 100))\n",
    "\n",
    "pp = 0\n",
    "nn = 0\n",
    "npp = 0\n",
    "pn = 0\n",
    "\n",
    "for i in range(iterations):\n",
    "    nextBatch, nextBatchLabels, counter = getTestBatch(counter)\n",
    "    predictions = sess.run(prediction, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "    for index in range(len(predictions)):\n",
    "        positive_sentiment, negative_sentiment = predictions[index][0], predictions[index][1]\n",
    "        if (positive_sentiment > negative_sentiment):\n",
    "            if ([1,0] == nextBatchLabels[index].tolist()):\n",
    "                pp = pp + 1\n",
    "            else:\n",
    "                npp = npp + 1\n",
    "        else:\n",
    "            if ([0,1] == nextBatchLabels[index].tolist()):\n",
    "                nn = nn + 1\n",
    "            else:\n",
    "                pn = pn + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "runlog = open(\"logs/{}.txt\".format(st),\"w+\")\n",
    "runlog.write(\"Sequence Length: {}\\n\".format(maxSeqLength))\n",
    "runlog.write(\"# of Dimensions: {}\\n\".format(numDimensions))\n",
    "runlog.write('# of files: {}\\n'.format(numFiles))\n",
    "runlog.write('Total # of words: {}\\n'.format(sum(numWords)))\n",
    "runlog.write('Average # of words: {}\\n'.format(sum(numWords)/len(numWords)))\n",
    "runlog.write('# of files per class: {}\\n'.format(minLength))\n",
    "runlog.write(\"Batch Size: {}\\n\".format(batchSize))\n",
    "runlog.write(\"Number of Classes: {}\\n\".format(numClasses))\n",
    "runlog.write(\"Training Iterations: {}\\n\".format(iterations))\n",
    "runlog.write(\"Testing Accuracy: {}\\n\".format((pp + nn) /(pp + nn + npp + pn)))\n",
    "runlog.close()\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
